---
title: "Thesis_GM_ADmetabolites_Code"
output: html_notebook
---

Package installation and loading

```{r}
## Packages (install and invoke)
pkgs <- c('car',
          'caret',
          'ada',
          'plyr',
          'dplyr',
          'randomForest',
          'party',
          'ROCR',
          'FMradio',
          'rags2ridges')
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}


##Load library
library(car)
library(caret)
library(rpart)
library(plyr)
library(dplyr)
library(rags2ridges)
library(ada)
library(randomForest)
library(party)
library(FMradio)
library(ROCR)
```

Data loading

```{r}
## Invoke data, get to know objects
data(ADdata)
```

Data preprocessing

```{r}
X <- as.matrix(scale(t(ADmetabolites)))

```

Projection to Latent Structures

```{r}
seed <- 123
set.seed(seed)
cov <- cor(X)

#Find redundant features
filter <- RF(cov)

#Filter out redundant features
filtered <- subSet(X, filter)

#Regularized correlation matrix estimation
M <- regcor(filtered)
```

```{r}
#Get the regularized correlation matrix of the filtered dataset
R <- M$optCor

#Get the Guttman bounds for R
Guttman.bounds <- dimGB(R)
```

```{r}
#Assess the proportion of cumulative variances for 86 factor solutions
dimVAR(R, maxdim=6)
```

```{r}
#Perform a Maximum Likelihood (ML) Factor Analysis of 84
mlfa <- mlFA(R, m=6)
thomson <- facScore(filtered,mlfa$Loadings,mlfa$Uniqueness)
```

## Data preparation for modelling
```{r}
X <- thomson

## Replace values of ApoEClass with 0 and 1 to facilitate machine learning
y <- as.character(sampleInfo$ApoEClass)
y <- replace(y, y == 'Class 1',0)
y <- replace(y, y == 'Class 2',1)
y <- as.factor(y)
```


```{r}
df <- cbind.data.frame(X,y)
set.seed(1635664)

split_index <- createDataPartition(df$y, p = 0.7, list = FALSE)

levels(df$y) <- make.names(levels(df$y))

train <- df[split_index, ]
test <- df[-split_index, ]
labels <- test$y
```

## Logistic Regression

```{r}
ctrl <- trainControl(method = "repeatedcv",
                     number = 5,
                     repeats = 100,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)

## Simple logistic model with meta-features as predictors
lr <- train(y ~.,
             train,
             method = "glm",
             metric = "ROC",
             trControl = ctrl)
#Predict
yhat.lr <- as.numeric(predict(lr, test))-1
labels <- as.numeric(labels)-1

#Create a ROC curve
pred.lr <- prediction(yhat.lr,labels)
perf.lr <- performance(pred.lr, "tpr", "fpr")
plot(perf.lr,
     colorize=TRUE,
     avg='threshold',
     lwd=2,
     main='ROC curves from 10-fold cross-validation')

yhat.lr <- as.factor(yhat.lr)
labels <- as.factor(labels)

cm.lr <- confusionMatrix(labels,yhat.lr, positive='1')
metrics.lr <- data.frame(cm.lr$byClass)
colnames(metrics.lr) <- 'Logistic Regression'
```


## Boosted Decision Tree

```{r}
tree <- train(y ~.,
             train,
             method = "ada",
             tuneLength=6,
             metric = "ROC",
             trControl = ctrl)
#Predict
yhat.tree <- as.numeric(predict(tree, test))-1
labels <- as.numeric(labels)-1

#Create a ROC curve
pred.tree <- prediction(yhat.tree,labels)
perf.tree <- performance(pred.tree, "tpr", "fpr")
plot(perf.tree,
     colorize=TRUE,
     avg='threshold',
     lwd=2,
     main='ROC curves from 10-fold cross-validation')

yhat.tree <- as.factor(yhat.tree)
labels <- as.factor(labels)

cm.tree <- confusionMatrix(labels,yhat.tree, positive='1')
metrics.tree <- data.frame(cm.tree$byClass)
metrics.tree <- rbind(metrics.tree,)
colnames(metrics.tree) <- 'Decision Tree'
```

```{r}
dtree <- tree(y~. -y, data =df)
summary(dtree)
plot(dtree)
text(dtree)
```

## Random Forest

```{r}
rf <- train(y ~.,
             train,
             method = "rf",
             tuneLength=6,
             metric = "ROC",
             trControl = ctrl)
#Predict
yhat.rf <- as.numeric(predict(rf, test))-1
labels <- as.numeric(labels)-1

#Create a ROC curve
pred.rf <- prediction(yhat.rf,labels)
perf.rf <- performance(pred.rf, "tpr", "fpr")
plot(perf.rf,
     colorize=TRUE,
     avg='threshold',
     lwd=2,
     main='ROC curves from 10-fold cross-validation')

yhat.rf <- as.factor(yhat.rf)
labels <- as.factor(labels)

cm.rf <- confusionMatrix(labels,yhat.rf, positive='1')
metrics.rf <- data.frame(cm.rf$byClass)
colnames(metrics.rf) <- 'Random Forest'
```

```{r}
#Create a data frame to store the metrics
metrics <- cbind(metrics.lr,metrics.tree,metrics.rf)


#Display the table of metrics
print(metrics)
```
