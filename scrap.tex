\section{R functions}
\paragraph{nested} \label{app:nested}
Function defined to iterate over a dataset of responses Y, fit a reduced (linear) model using the covariates passed to \texttt{\dots} and a full model using the covariates and variable x. It extracts the p-values of the ANCOVA F-tests, corrects for FDR, filters those below .05 and displays them. Then, it extracts the coefficients and p-values of their t-tests and consolidates the values in two rows per  metabolite in a table.
\begin{verbatim}
nested <- function(Y, x, ...) {
    x <- as.factor(x)
    df <- cbind(Y, x, ...)
    ncol <- ncol(Y)
    covariates <- names(...)
    F_tests <- furrr::future_map(df[, 1:ncol], ~ {
      frm <- as.formula(paste0(".x ~", paste(covariates, collapse = "+")))
      rm <- lm(frm, data = df)
      ffm <- as.formula(paste0(".x ~ x +", paste(covariates, collapse = "+")))
      fm <- lm(ffm, data = df)
      anova(rm, fm)
    })
    # Correction for Multiple Testing
    # Create a list to store the p-values
    p_values <- list(1:ncol)
    # Extract the p-values of the F-tests from the anova summaries list and store them in p_values
    for (i in 1:ncol) {
      p_values[[i]] <- F_tests[[i]][["Pr(>F)"]][[2]]
    }
    # Coerce p_values to dataframe and transpose it
    p_values <- t(data.frame(p_values))

    # Set as row names the metabolites
    p_values <- data.frame(p_values, row.names = colnames(Y))

    # Calculate the FDR-adjusted p-values
    p_values$p_adj <- p.adjust(p_values[, ], method = "fdr", n=230 )

    # Filter out the non-significant (a=0.05) FDR-adjusted p-values
    sig <- as.data.frame(dplyr::filter(p_values, p_values < 0.05))
    sig <- sig[order(sig$p_adj), ]
    cat("Significant F-tests: \n")
    print(sig)
    cat("\nDose effects on metabolites:")
    knitr::kable(sig)
    summaries <- furrr::future_map(df[, rownames(sig)], ~ {
      f <- as.formula(paste0(".x ~ x +", paste(covariates, collapse = "+")))
      mdl <- lm(f, data = df)
      summary(mdl)$coefficients[1:length(table(x)), ]
    })
    summaries <- lapply(summaries, function(x) {
      x <- x[, -c(2, 3)]
      x <- t(x)
    })
    summaries <- plyr::ldply(summaries, id = 1:2)
    return(knitr::kable(summaries, table.attr = "style='width:30%;'"))
}
\end{verbatim}

\paragraph{multifit} \label{app:multifit}
\begin{verbatim}
multifit <- function(X,
                     y,
                     model,
                     ctrl = NULL,
                     grid = NULL,
                     seed = 87654, ...) {
    set.seed(seed)
    # Merge X and y into df
    df <- cbind.data.frame(X, y)
    # Train the model
    mdl <- caret::train(df[, 1:ncol(X)], df$y,
        method = model,
        tuneGrid = grid,
        trControl = ctrl,
        metric = "logLoss",
        ...
    )
    return(mdl)
}
\end{verbatim}

\paragraph{evaluate} \label{app:evaluate}

\begin{verbatim}
evaluate <- function(model){
    obs <- model$pred$obs
    preds <- model$pred$pred
    # Get the multi-class ROC curves
    ys <- as.numeric(obs) - 1
    yhats <- as.numeric(preds) - 1
    roc <- multiclass.roc(response = ys, predictor = yhats, quiet = T, legacy.axes = T)
    print(roc$auc)
    names(roc$rocs) <- c("ADE4-AD", "ADE4-SCDE4", "ADE4-SCD", "AD-SCDE4", "AD-SCD", "SCDE4-SCD")
    g <- ggroc(roc$rocs, legacy.axes = T) + scale_color_tableau() + theme_tufte() + guides(color = guide_legend(title = "ROC curves"))
    ggplotly(g)
    cat("\n")
    # Create a confusion matrix and get performance metrics from caret
    cm <- confusionMatrix(reference = obs, data = preds, mode = "everything")
    print(cm)
}    
\end{verbatim}