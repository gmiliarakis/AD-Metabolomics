---
title: "RQii - Classification of metabolites on ApoE class"
output:
  html_document: 
    toc: yes
    toc_depth: 4
    theme: flatly
  pdf_document:
    toc: yes
  html_notebook: 
    toc: yes
    theme: flatly
    toc_depth: 5
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

```{r, include = FALSE}
require(caret)
require(dplyr)
require(e1071)
require(FMradio)
require(pROC)
require(xgboost)
require(rpart)
require(DMwR2)
require(nnet)
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = NA, warning = FALSE
)
```
```{r multifit}
multifit <- function(
                X,
                y,
                model,
                ctrl = NULL,
                grid = NULL,
                seed = 87654, ...) {
  set.seed(seed)
  # Merge X and y into df
  df <- cbind.data.frame(X, y)
  # Train the model
  mdl <- caret::train(df[, 1:ncol(X)], df$y,
    method = model,
    tuneGrid = grid,
    trControl = ctrl,
    metric = "logLoss",
    ...
  )
  # Create a confusion matrix and get performance metrics from caret
  obs <- mdl$pred$obs
  preds <- mdl$pred$pred
  cm <- confusionMatrix(reference = obs, data = preds, mode = "everything")
  # Predictions
  ys <- as.numeric(obs) -1
  yhats <- as.numeric(preds) -1
  roc <- multiclass.roc(response = ys, predictor = yhats)
  out <- list("cm" = cm, "roc" = roc, "model" = mdl)
  return(out)
}
```

### Preparation
```{r multi_preparation}
load("data/data.Rdata")
X <- scale(df[, 1:230])
y <- df$target

Xclin = cbind.data.frame(X, clin_dummy)


ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 15,
  savePredictions = "final",
  classProbs = T,
  summaryFunction = multiClassSummary,
  selectionFunction = best,
  search = "random",
  sampling = "smote"
)
```

### Fitting a benchmark model: clinical characteristics only

```{r mlogit}
basic <- multifit(
  X = clin_dummy,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  grid = expand.grid(decay = 0),
  trace = F
)
basic$cm
basic$roc
ggroc(basic$roc$rocs)
```
### Regularized Multinomial Regression adding 230 metabolites

```{r}
mlr <- multifit(
  X = Xclin,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  grid = expand.grid(decay = 10),
  trace = F
)
mlr$cm
mlr$roc
ggroc(mlr$roc$rocs)
```

### Projection to Latent Factors

```{r get_thomson}
project <- function(X, m, seed) {
  set.seed(seed)
  X <- scale(as.matrix(df[,1:230]))
  cov <- cor(X)

  # Find redundant features
  filter <- RF(cov)

  # Filter out redundant features
  filtered <- subSet(X, filter)

  # Regularized correlation matrix estimation
  M <- regcor(filtered)

  # Get the regularized correlation matrix of the filtered dataset
  R <- M$optCor

  mlfa <- mlFA(R, m = 6)
  thomson <- facScore(filtered, mlfa$Loadings, mlfa$Uniqueness)
  return(thomson)
}
```

```{r}
thomson <- project(X, 6, seed = 1234)
X <- cbind(clin_dummy, thomson)
```
#### Multinomial Logistic Regression adding 6 factors
```{r }
mlrf <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  grid = expand.grid(decay = 0)
)
mlrf$cm
mlrf$roc
ggroc(mlrf$roc$rocs)
```

#### Decision Tree

```{r multi_tree}
tree <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = expand.grid(maxdepth=3)
)
tree$cm
tree$roc
ggroc(tree$roc$rocs)
```

#### XGBoost Forest

```{r }
xgb <- multifit(
  X = X,
  y = y,
  model = "xgbTree",
  ctrl = ctrl,
  grid = xgb.grid
)
xgb$cm
xgb$roc
ggroc(xgb$roc$rocs)
```
## Model Comparison
Based on the AUC as global performance metric, the best performing model is the full multinomial regression model (MLR1) with the background clinical characteristics (Ab42, tau, p-tau levels, MMSE score, age at diagnosis, sex, BMI, smoking status, alchohol consumption, hypertension (plus medication), hypercholesterolemia (plus medication), medication for diabetes melitus, depression and clotting disorders) plus the 230 serum metabolites (AUC = 0.8364). MLR1 performs slightly better than the benchmark model (MLR0) fitting only the clinical characteristics (AUC = 0.831). The Xtreme Gradient Booster (XGB) performs slightly worse than MLR1 with the clinical characteristics plus the 6-factor projection of the metabolites. MLR2, with the clinical characteristics and the 6 factors also performs better than the MLR0 (AUC = 0.82).

Concluion:
1. Adding serum metabolite information (either the full 230-metabolite matrix or its 6-factor projection) seems to increase the discriminatory power of the models.

2. Fitting 6 ML-estimated factors obtained by the FMradio package (cummulatively explaining 30% of variace) yields increased classification performance, serving as a valuable dimension reduction technique for high-dimensional data.

3. Looking at the ROC curves, the models were able to discriminate better among certain classes, compared to others.

```{r}
aucs <- c(MLR0 = basic$roc$auc, MLR1 = mlr$roc$auc, MLR2 = mlrf$roc$auc, TREE = tree$roc$auc, XGB = xgb$roc$auc)
knitr::kable(t(aucs))
```