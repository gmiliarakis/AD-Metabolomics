---
title: "Analysis"
output:
  html_document: 
    toc: yes
    toc_depth: 4
    theme: flatly
  pdf_document:
    toc: yes
  html_notebook: 
    toc: yes
    theme: flatly
    toc_depth: 5
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

```{r, include = FALSE}
require(caret)
require(dplyr)
require(e1071)
require(FMradio)
require(pROC)
require(rags2ridges)
require(xgboost)
require(rpart)
require(ggthemes)
require(DMwR2)
require(nnet)
load("data/data.Rdata")
load("data/clinical.Rdata")
```
## RQii - Classification of metabolites on ApoE class

```{r multifit}
multifit <- function(
                X,
                y,
                model,
                ctrl = NULL,
                grid = NULL,
                seed = 123, ...) {
  set.seed(seed)
  # Merge X and y into df
  df <- merge.data.frame(X, y)

  # # calculate what fraction of the total each class has
  # fraction <- table(y)/length(y)
  # # assign 1 - that value to a "weights" vector
  # weights <- 1 - fraction[as.character(y)]
  # Train the model
  mdl <- caret::train(df[, 1:ncol(X)], df$y,
    method = model,
    tuneGrid = grid,
    trControl = ctrl,
    metric = "Mean_Balanced_Accuracy",
    # weights = weights,
    ...
  )
  # Create a confusion matrix and get performance metrics from caret
  obs <- mdl$pred$obs
  preds <- mdl$pred$pred
  cm <- confusionMatrix(reference = obs, data = preds, mode = "everything")
  # Predictions
  ys <- as.numeric(obs) -1
  yhats <- as.numeric(preds) -1
  roc <- multiclass.roc(response = ys, predictor = yhats)
  out <- list("cm" = cm, "roc" = roc, "model" = mdl)
  return(out)
}
```

### Using 230 metabolites
```{r multi_preparation}
X <- df[,1:230]
y <- df$target
levels(y) <- make.names(levels(y))
# clnr <- as.data.frame(purrr::map(clinical[, 1:ncol(clinical)], ~ as.numeric(.x)))
# clnr <- as.data.frame(clnr)
# X <- cbind(df[, 1:230], clnr)

ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 1,
  savePredictions = "final",
  summaryFunction = multiClassSummary,
  selectionFunction = best,
  search = "random",
  sampling = "up"
)
```

#### Penalised Multinomial Logistic Regression

```{r mlogit}
mlr <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  grid = expand.grid(decay=0.01),
  preProcess = c("center", "scale", "corr"),
  trace = F
)
mlr$cm
```

#### Decision Tree

```{r }
tree <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = expand.grid(maxdepth = 2),
  preProcess = c("center", "scale", "corr")
)
tree$cm
```

#### Random Forest

```{r multi_xgb}
rf <- multifit(
  X = X,
  y = y,
  model = "xgbTree",
  ctrl = ctrl,
  tuneLength = 1,
  preProcess = c("center", "scale", "corr")
)
rf$cm
```

### Projection to Latent Factors

```{r get_thomson, eval =FALSE, include=FALSE}
project <- function(X, m, seed) {
  set.seed(seed)
  X <- scale(as.matrix(df[,1:230]))
  cov <- cor(X)

  # Find redundant features
  filter <- RF(cov)

  # Filter out redundant features
  filtered <- subSet(X, filter)

  # Regularized correlation matrix estimation
  M <- regcor(filtered)

  # Get the regularized correlation matrix of the filtered dataset
  R <- M$optCor

  mlfa <- mlFA(R, m = 6)
  thomson <- facScore(filtered, mlfa$Loadings, mlfa$Uniqueness)
  return(thomson)
}
```

```{r}
X <- project(X, 6, seed = 1234)
```
#### Multinomial Logistic Regression

```{r }
# X <- cbind(clnr, thomson)
mlrf <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  grid = expand.grid(decay = 0)
)
mlrf$cm
plot.roc(mlrf$roc)
```

#### Decision Tree

```{r multi_tree}
mtreef <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = tree$model$bestTune
)
mtreef$cm
```

#### XGBoost Forest

```{r }
mrff <- multifit(
  X = X,
  y = y,
  model = "xgbTree",
  ctrl = ctrl,
  tuneLength = 1
)
mrff$cm
```