---
title: "Analysis"
output:
  html_document: 
    toc: yes
    toc_depth: 4
    theme: flatly
  pdf_document:
    toc: yes
  html_notebook: 
    toc: yes
    theme: flatly
    toc_depth: 5
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = "", warning = FALSE
)
```

```{r packages, include=FALSE}
require(caret)
require(dplyr)
require(e1071)
require(FMradio)
require(pROC)
require(rags2ridges)
require(xgboost)
require(ggthemes)
require(DMwR2)
require(globaltest)
require(GlobalAncova)
require(heatmaply)
require(nnet)
```

## Data Exploration

The (interactive) correlation heatmap reveals very high correlation among TG compounds.

```{r heatmap}
load("./data.Rdata")
X <- df[df$Diagnosis == "Probable AD", 1:230]
C <- round(cor(X), 2)

heatmaply_cor(C, color = viridis, plot_method = "plotly", dendrogram = F, reorderfun = sort.default(d,w), main = "Correlation Heatmap", file = "heatmap.html", colorbar_thickness = 15, colorbar_len = 0.5)
```

## RQi: Differential expression of metabolites per ApoE genotype

### Global test

Performing a Global Test on the serum metabolites of AD patients, correcting for sex (Ho: E4 status has no effect on metabolite levels, Ha: it has an effect), yields a significant difference (p = 0.046) between E4 carriers and non-carriers. Testing if the counts of E4 alleles have an effect on metabolite levels showed no significant nuance.

```{r gt}
load("data.Rdata")
AD <- subset(df, Diagnosis == "Probable AD")
AD$sex <- as.numeric(AD$sex) -1
# Binary outcome
gt.b <- globaltest::gt(E4 ~ 1, E4 ~ . -APOE -Diagnosis, data = AD)
gt.b

# Multinomial outcome
full$Diagnosis <- as.numeric(full$Diagnosis) - 1
full$target[full$Diagnosis == 1 & full$E4 == 1] <- "AD with at least 1 ApoE4"
full$target[full$Diagnosis == 1 & full$E4 == 0] <- "AD without ApoE4"
full$target[full$Diagnosis == 0 & full$E4 == 1] <- "SCD with at least 1 ApoE4"
full$target[full$Diagnosis == 0 & full$E4 == 0] <- "SCD without ApoE4"
df$target <-  full$target
df$target <- as.factor(df$target)

AD$APOE <- as.factor(AD$APOE)
gt.m <- globaltest::gt(target ~ 1, target ~ . , data = df)
httpgd::hgd()

gt.m
covariates(gt.m)
```

```{r}
df$Diagnosis <- df$sex <- df$APOE <- df$E4 <- NULL
df[,232:245] <- NULL
gGA <- gGlobalAncova(df[,1:230], formula.full = ~target, formula.red = ~1, model.dat = df, perm =1000
)
gGA
# get a hierarchy for variables
dend <- as.dendrogram(hclust(dist(t(df[,1:230]))))
# hierarchical test
set.seed(555)
res <- gGlobalAncova.hierarchical(df[,1:230], H = dend, formula.full = ~target, model.dat = df, alpha = 0.05, perm = 100)
results(res)
# get names of significant clusters
sigEndnodes(res)
```


```{r}
anova <- function(Y, x, ...) {
  ### Analysis of Variance (ANOVA)
  df <- cbind(Y, x, ...)
  ncol <- ncol(Y)
  covariates <- names(...)
  summaries <- purrr::map(df[, 1:ncol], ~ {
    frm <- as.formula(paste0(".x ~", paste(covariates, collapse = "+")))
    rm <- lm(frm, data = df)
    ffm <- as.formula(paste0(".x ~ x +", paste(covariates, collapse = "+")))
    fm <- lm(ffm, data = df)
    anova(rm, fm)
  })
  ## Correction for Multiple Testing
  # Create a list to store the p-values
  p_values <- list(1:ncol)
  # Extract the p-values of the F-tests from the aov summaries list and store them in p_values
  for (i in 1:ncol) {
    p_values[[i]] <- summaries[[i]][["Pr(>F)"]][[2]]
  }
  # Coerce p_values to dataframe and transpose it
  p_values <- t(data.frame(p_values))

  # Set as row names the metabolites
  p_values <- data.frame(p_values, row.names = colnames(Y))

  # Calculate the FDR-adjusted p-values
  p_values$p_adj <- p.adjust(p_values[, ], method = "fdr")
  # Filter out the non-significant (a=0.05) FDR-adjusted p-values
  return(dplyr::filter(p_values, p_values < 0.05))
}
```

```{r}
Y <- df[, 1:230]
clinical$V_MMSE <- NULL
gentest(Y, target, clinical)
```

## RQii - Classification of metabolites on ApoE class
### Multinomial Classification of number of ApoE E4 alleles based on metabolites

```{r multifit}
multifit <- function(
                X,
                y,
                model,
                ctrl = NULL,
                grid = NULL,
                seed = 123, ...) {
  set.seed(seed)
  # Merge X and y into df
  df <- merge.data.frame(X, y)

  # Train the model
  mdl <- caret::train(df[, 1:ncol(X)], df$y,
    method = model,
    tuneGrid = grid,
    trControl = ctrl,
    metric = "logLoss",
    ...
  )
  # Create a confusion matrix and get performance metrics from caret
  obs <- mdl$pred$obs
  preds <- mdl$pred$pred
  cm <- confusionMatrix(reference = obs, data = preds, mode = "everything")
  # Predictions
  ys <- as.numeric(obs) -1
  yhats <- as.numeric(preds) -1
  roc <- multiclass.roc(response = ys, predictor = yhats)
  out <- list("cm" = cm, "roc" = roc, "model" = mdl)
  return(out)
}
```
#### Using 230 metabolites in AD
```{r multi_preparation}
X <- df[,1:230]
y <- df$target
levels(y) <- make.names(levels(y))
clnr <- as.data.frame(purrr::map(clinical[, 1:ncol(clinical)], ~ as.numeric(.x)))
clnr <- as.data.frame(clnr)
X <- cbind(df[, 1:230], clnr)
require(ROSE)
ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 1,
  classProbs = TRUE,
  summaryFunction = multiClassSummary,
  savePredictions = TRUE,
  sampling = "smote"
)
```

##### Multinomial Logistic Regression

```{r mlogit}
mlr <- multifit(
  X = clnr,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  grid = expand.grid(decay=0.1)
)
mlr$cm
mlrm <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  grid = expand.grid(decay=0.1),
preProcess =  c("center","scale")
)
mlrm$cm
table(df$target)
```

##### Decision Tree

```{r }
require(C50)

tree <- multifit(
  X = clnr,
  y = y,
  model = "C5.0Tree",
  ctrl = ctrl,
  grid = NULL,
  tuneLength = 2
)
tree$cm
```

##### Random Forest

```{r multi_xgb}
rf <- multifit(
  X = clnr,
  y = y,
  model = "rf",
  ctrl = ctrl,
  tuneLength = 5
)
rf$cm
```

```{r}
#Get a performance metrics table
metrics <- cbind(mlr$cm$byClass[3,], tree$cm$byClass[3,], rf$cm$byClass[3,])
metrics
#Plot ROC curves
rocs <- list(mlr$roc, tree$roc, rf$roc)
# Generate labels
labels <- paste0(names(metrics), ", AUC = ", paste(round(metrics[12, ], 2)))
```

#### Projection to Latent Factors

```{r get_thomson, eval =FALSE, include=FALSE}
project <- function(X, m, seed) {
  set.seed(seed)
  X <- scale(as.matrix(df[,1:230]))
  cov <- cor(X)

  # Find redundant features
  filter <- RF(cov)

  # Filter out redundant features
  filtered <- subSet(X, filter)

  # Regularized correlation matrix estimation
  M <- regcor(filtered)

  # Get the regularized correlation matrix of the filtered dataset
  R <- M$optCor

  mlfa <- mlFA(R, m = 6)
  thomson <- facScore(filtered, mlfa$Loadings, mlfa$Uniqueness)
  return(thomson)
}
```

```{r}

```
##### Multinomial Logistic Regression

```{r }

ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 1,
  classProbs = TRUE,
  summaryFunction = multiClassSummary,
  savePredictions = TRUE,
  sampling = "up"
)
X <- cbind(clnr, thomson)
mlrf <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  grid = expand.grid(decay = 0.01778279)
)
mlrf$cm
```

##### Decision Tree

```{r multi_tree}
mtreef <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = mtree$model$bestTune
)
mtreef$cm
```

##### XGBoost Forest

```{r }
require(gbm)
mrff <- multifit(
  X = X,
  y = y,
  model = "gbm",
  ctrl = ctrl,
  grid = expand.grid(interaction.depth = 1,
                        n.trees = 50,
                        shrinkage = 0.01,
                        n.minobsinnode = 5)
)
mrff$cm
```

```{r}
# Get a performance metrics table
multimetricsf <- cbind(mlrf$cm$byClass[3, ], mtreef$cm$byClass[3, ], mrff$cm$byClass[3, ])
names(multimetricsf) <- names(metrics)
multimetricsf
```

## Network Analysis

Code from rags2ridges

```{r preparation}
# Store all observations of Class 1 in C1
C1 <- scale(df[df$APOE == "E4NO",1:230])
# Store all observations of Class 2 in C2
C2 <- scale(df[APOE == "E4YES",1:230])

# Get the covariance matrices of C1 and C2
S1 <- covML(C1)
S2 <- covML(C2)

# Store them in a list
S <- list(S1 = S1, S2 = S2)

# Get the total number of samples
n <- c(nrow(S1), nrow(S2))

# Create a list of fused covariance matrices T
Ts <- default.target.fused(Slist = S, ns = n, type = "DUPV")
```

```{r, eval=FALSE}
# Get the optimal lambdas per class and fused with 10-fold CV
set.seed(8910)
# optf <- optPenalty.fused(
#   Ylist = Ys,
#   Tlist = Ts,
#   lambda = as.matrix(cbind(
#     c("ridge1", "fusion"),
#     c("fusion", "ridge2")
#   )),
#   cv.method = "kCV",
#   k = 10,
#   verbose = FALSE
# )
```

```{r sparsify, echo = FALSE}
# Create a list of the two-class data Y
Ys <- list(C1 = C1, C2 = C2)
Ps <- optP.fused$Plist
# Get the sparsified high precision matrices, correcting FDR at .001
P0s <- sparsify.fused(Ps,
  threshold = "localFDR",
  FDRcut = 0.999,
  verbose = FALSE
)
```

```{r GGMs per class and diff, message=FALSE, echo = FALSE}
# Merge the sparse high precision matrices
TST <- Union(P0s$C1$sparseParCor, P0s$C2$sparseParCor)
PCclass1 <- TST$M1subset
PCclass2 <- TST$M2subset

# Create a color map per metabolite class
Colors <- rownames(PCclass2)
Colors[grep("Amine", rownames(PCclass2))] <- "lightblue"
Colors[grep("Org.Acid", rownames(PCclass2))] <- "orange"
Colors[grep("Lip", rownames(PCclass2))] <- "yellow"
Colors[grep("Ox.Stress", rownames(PCclass2))] <- "purple"


set.seed(111213)
opar <- par(mfrow = c(1, 3))
# Plot the sparsified ridge matrix of AD Class 2
Coords <- Ugraph(PCclass2,
  type = "fancy", lay = "layout_with_fr",
  Vcolor = Colors, prune = FALSE, Vsize = 7, Vcex = 0.3,
  main = "AD Class 2"
)
# Plot he sparsified ridge matrix of AD Class 1
Ugraph(PCclass1,
  type = "fancy", lay = NULL, coords = Coords,
  Vcolor = Colors, prune = FALSE, Vsize = 7, Vcex = 0.3,
  main = "AD Class 1"
)

# Plot the differential network
DiffGraph(PCclass1, PCclass2,
  lay = NULL, coords = Coords,
  Vcolor = Colors, Vsize = 7, Vcex = 0.3,
  main = "Differential Network"
)
par(opar)
```

```{r centrality}
PC0list <- list(PCclass1 = PCclass1, PCclass2 = PCclass2)
# Get the network statistics
NetStats <- GGMnetworkStats.fused(PC0list)

# Get the centrality degree scores for each class
DegreesAD1 <- data.frame(rownames(NetStats), NetStats$PCclass1.degree)
DegreesAD2 <- data.frame(rownames(NetStats), NetStats$PCclass2.degree)

# Order and show the centrality degree scores
DegreesAD1o <- DegreesAD1[order(DegreesAD1[, 2], decreasing = TRUE), ]
DegreesAD2o <- DegreesAD2[order(DegreesAD2[, 2], decreasing = TRUE), ]
head(DegreesAD1o, 7)
head(DegreesAD2o, 7)
```

```{r communities}
# Get the communities per class
set.seed(141516)
opar <- par(mfrow = c(1, 2))
CommC1 <- Communities(PCclass1,
  Vcolor = Colors,
  Vsize = 7, Vcex = 0.3, main = "Modules AD Class 1"
)

CommC2 <- Communities(PCclass2,
  Vcolor = Colors,
  Vsize = 7, Vcex = 0.3, main = "Modules AD Class 2"
)
par(opar)
```

```{r degree density plot }
# Plot the densities of centrality degree scores
plot(density(DegreesAD1[, 2]),
  col = "blue", xlim = c(-1, 8), xlab = "Degree", main = ""
)
lines(density(DegreesAD2[, 2]),
  col = "red"
)
legenda <- c("AD class 1", "AD class 2")
legend(5, 0.5,
  legend = legenda, 
  lwd = rep(1, 2), lty = rep(1, 2), col = c("blue", "red"), cex = 0.7
)
```

```{r wilcoxon rank sum }
# Perform a Wilcoxon signed rank test to test if the centrality degree scores are different between the classes
wilcox.test(DegreesAD1[, 2],
  DegreesAD2[, 2],
  paired = TRUE, alternative = "less"
)
```
