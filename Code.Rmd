---
title: "Analysis"
output:
  html_document: 
    toc: yes
    toc_depth: 4
    theme: darkly
    fig_width: 6
  pdf_document:
    toc: yes
  html_notebook: 
    toc: yes
    theme: darkly
    toc_depth: 5
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = "", fig.width = 6, fig.height = 6, warning = FALSE
)
```

```{r packages, include=FALSE}
require(caret)
require(dplyr)
require(e1071)
require(FMradio)
require(pROC)
require(rags2ridges)
require(rpart)
require(ranger)
require(ggthemes)
require(DMwR2)
```

## Data loading

```{r data loading, echo=FALSE}
# Invoke data
load("data.Rda")
load("ADdata.Rdata")
```

## Differential expression of metabolites per ApoE genotype

### Data Preparation

```{r Y}
# Transpose, standardize and store the metabolite data in Y
Y <- as.matrix(ADmets)
```

```{r df}
# Store the ApoE genotype in APOE as a factor
APOE <- as.factor(geno$APOEb)
sex <- as.factor(geno$sex)
df <- cbind.data.frame(Y, APOE, sex)
```

### Analysis of Variance (ANOVA)

```{r aov}
# Store the ANOVA model summaries in summaries
summaries <- purrr::map(df[, 1:230], ~ summary(aov(.x ~ df$APOE)))
```

#### Correction for Multiple Testing

```{r FDR adjust}
## Extract and adjust p-values for FDR control
# Create a list to store the p-values
p_values <- list(1:230)
# Extract the p-values of the F-tests from the aov summaries list and store them in p_values
for (i in 1:230) {
  p_values[[i]] <- summaries[[i]][[1]][["Pr(>F)"]][[1]]
}
# Coerce p_values to dataframe and transpose it
p_values <- t(data.frame(p_values))
# Set as row names the metabolites
p_values <- data.frame(p_values, row.names = colnames(Y))
# Calculate the FDR-adjusted p-values
p_values$p_adj <- p.adjust(p_values[, ], method = "fdr")
```


```{r}
# Filter out the non-significant (a=0.05) FDR-adjusted p-values
dplyr::filter(p_values, p_adj < 0.05)
```

## Classification of metabolites on ApoE class
```{r fit function def}
## Function fit
fit <- function(title,
                X,
                y,
                split = 0.8,
                model,
                times,
                ctrl = trainControl(
                  method = "cv", number = 10,
                  classProbs = TRUE, summaryFunction = twoClassSummary,
                  sampling = "smote"
                ),
                grid = NULL,
                seed = 123,
                metrics = matrix(nrow = 11, ncol = times), ...) {
  # Merge X and y into df
  df <- cbind.data.frame(X, y)
  ys <- yhats <- c()
  # Perform 10-fold CV repeated 100 times
  for (i in 1:times) {
    set.seed(seed + i) # Set a different seed for each iteration
    # Create a matrix with the training indices
    split_index <- createDataPartition(df$y, p = split, list = FALSE)
    # Create the training set
    train <- df[split_index, ]
    # Create the test set
    test <- df[-split_index, ]
    # Store the test y in labels
    labels <- test$y
    ys <- c(ys, as.numeric(labels) - 1)
    # Train the model
    mdl <- caret::train(train[, 1:ncol(X)], train$y,
      method = model,
      tuneGrid = grid,
      trControl = ctrl,
      metric = 'ROC',...
    )
    # Create a confusion matrix and get performance metrics from caret
    cm <- confusionMatrix(labels, predict(mdl, test), positive = "E4YES")
    # Store the model performance metrics in the cumulative data frame
    metrics[, i] <- cm$byClass
    # Predictions
    yhat <- predict(mdl, test, type = "prob")[, 2]
    yhats <- c(yhats, yhat)
  }
  roc <- roc(ys,
    yhats,
    levels = c(0, 1),
    # arguments for ci
    ci = TRUE, boot.n = 1000, ci.alpha = 0.95
  )
  metrics <- data.frame(c(rowMeans(metrics, na.rm = TRUE), roc$auc),
    row.names = c(names(cm$byClass), "AUC")
  )
  names(metrics) <- title
  out <- list("metrics" = metrics, "roc" = roc, "model" = mdl)
  return(out)
}
```

### Original data

```{r fit_original}
k <- 100
## Logistic Regression
lr <- fit(
  title = "Logistic Regression",
  X = X,
  y = APOE,
  model = "glm",
  times = k
)

## Decision Tree
tree <- fit(
  title = "Decision Tree",
  X = X,
  y = apoe,
  model = "rpart2",
  grid=expand.grid(maxdepth = 5),
  times = k
)

## Random Forest
rf <- fit(
  title = "Random Forest",
  X = X,
  y = APOE,
  model = "ranger",
  ctrl = trainControl(
                  method = "cv", number = 10,
                  classProbs = TRUE, summaryFunction = twoClassSummary,
                  sampling = "smote"
                ),
                grid = NULL,
  tuneLength = 2,
  times = k,
  num.trees = 100
)

metrics <- cbind(lr$metrics, tree$metrics, rf$metrics)
rocs <- list(lr$roc, tree$roc, rf$roc)

# Generate labels
labels <- paste0(names(metrics), " AUC = ", paste(round(metrics[12, ], 2)))
# plot on a single plot with AUC in labels
boxplot(metrics)
ggroc(rocs) +
  theme_clean() +
  scale_color_tableau(labels=labels)
```

### Projection to Latent Factors

```{r get_thomson, eval =FALSE, include=FALSE}
project <- function(X, m, seed) {
  set.seed(seed)
  X <- scale(as.matrix(X))
  cov <- cor(X)
  
  # Find redundant features
  filter <- RF(cov)
  
  # Filter out redundant features
  filtered <- subSet(X, filter)
  
  # Regularized correlation matrix estimation
  M <- regcor(filtered)
  
  # Get the regularized correlation matrix of the filtered dataset
  R <- M$optCor
  
  mlfa <- mlFA(R, m = m)
  thomson <- facScore(filtered, mlfa$Loadings, mlfa$Uniqueness)
  return(thomson)
}
```

```{r fit_thomson, warning=FALSE}
#Set k for repeats
k <- 100
## Logistic Regression
lrf <- fit(
  title = "Logistic Regression",
  X = thomson,
  y = apoe,
  model = "glm",
  times = k,
  grid = NULL
)

## Decision Tree
treef <- fit(
  title = "Decision Tree",
  X = thomson,
  y = apoe,
  model = "rpart2",
  grid = expand.grid(maxdepth = 5),
  times = k
)

## Ensemble Classifiers
rff <- fit(
  title = "Random Forest",
  X = thomson,
  y = apoe,
  model = "ranger",
  ctrl = trainControl(
                  method = "cv", number = 10,
                  classProbs = TRUE, summaryFunction = twoClassSummary,
                  sampling = "smote"
                ),
                grid = NULL,
  tuneLength = 2,
  times = 10,
  num.trees = 50
)

metricsf <- cbind(lrf$metrics, treef$metrics, rff$metrics)
rocsf <- list(lrf$roc, treef$roc, rff$roc)

# plot on a single plot with AUC in labels
ggroc(rocsf) +
  theme_clean() +
  scale_color_tableau(labels= labels)
```

## Network Analysis

Code from rags2ridges

```{r preparation}
# Store all observations of Class 1 in C1
C1 <- scale(df[df$APOE == "E4NO",1:230])
# Store all observations of Class 2 in C2
C2 <- scale(df[APOE == "E4YES",1:230])

# Get the covariance matrices of C1 and C2
S1 <- covML(C1)
S2 <- covML(C2)

# Store them in a list
S <- list(S1 = S1, S2 = S2)

# Get the total number of samples
n <- c(nrow(S1), nrow(S2))

# Create a list of fused covariance matrices T
Ts <- default.target.fused(Slist = S, ns = n, type = "DUPV")
```

```{r, eval=FALSE}
# Get the optimal lambdas per class and fused with 10-fold CV
set.seed(8910)
# optf <- optPenalty.fused(
#   Ylist = Ys,
#   Tlist = Ts,
#   lambda = as.matrix(cbind(
#     c("ridge1", "fusion"),
#     c("fusion", "ridge2")
#   )),
#   cv.method = "kCV",
#   k = 10,
#   verbose = FALSE
# )
```

```{r sparsify, echo = FALSE}
# Create a list of the two-class data Y
Ys <- list(C1 = C1, C2 = C2)
Ps <- optP.fused$Plist
# Get the sparsified high precision matrices, correcting FDR at .001
P0s <- sparsify.fused(Ps,
  threshold = "localFDR",
  FDRcut = 0.999,
  verbose = FALSE
)
```

```{r GGMs per class and diff, message=FALSE, echo = FALSE}
# Merge the sparse high precision matrices
TST <- Union(P0s$C1$sparseParCor, P0s$C2$sparseParCor)
PCclass1 <- TST$M1subset
PCclass2 <- TST$M2subset

# Create a color map per metabolite class
Colors <- rownames(PCclass2)
Colors[grep("Amine", rownames(PCclass2))] <- "lightblue"
Colors[grep("Org.Acid", rownames(PCclass2))] <- "orange"
Colors[grep("Lip", rownames(PCclass2))] <- "yellow"
Colors[grep("Ox.Stress", rownames(PCclass2))] <- "purple"


set.seed(111213)
opar <- par(mfrow = c(1, 3))
# Plot the sparsified ridge matrix of AD Class 2
Coords <- Ugraph(PCclass2,
  type = "fancy", lay = "layout_with_fr",
  Vcolor = Colors, prune = FALSE, Vsize = 7, Vcex = 0.3,
  main = "AD Class 2"
)
# Plot he sparsified ridge matrix of AD Class 1
Ugraph(PCclass1,
  type = "fancy", lay = NULL, coords = Coords,
  Vcolor = Colors, prune = FALSE, Vsize = 7, Vcex = 0.3,
  main = "AD Class 1"
)

# Plot the differential network
DiffGraph(PCclass1, PCclass2,
  lay = NULL, coords = Coords,
  Vcolor = Colors, Vsize = 7, Vcex = 0.3,
  main = "Differential Network"
)
par(opar)
```

```{r centrality}
PC0list <- list(PCclass1 = PCclass1, PCclass2 = PCclass2)
# Get the network statistics
NetStats <- GGMnetworkStats.fused(PC0list)

# Get the centrality degree scores for each class
DegreesAD1 <- data.frame(rownames(NetStats), NetStats$PCclass1.degree)
DegreesAD2 <- data.frame(rownames(NetStats), NetStats$PCclass2.degree)

# Order and show the centrality degree scores
DegreesAD1o <- DegreesAD1[order(DegreesAD1[, 2], decreasing = TRUE), ]
DegreesAD2o <- DegreesAD2[order(DegreesAD2[, 2], decreasing = TRUE), ]
head(DegreesAD1o, 7)
head(DegreesAD2o, 7)
```

```{r communities}
# Get the communities per class
set.seed(141516)
opar <- par(mfrow = c(1, 2))
CommC1 <- Communities(PCclass1,
  Vcolor = Colors,
  Vsize = 7, Vcex = 0.3, main = "Modules AD Class 1"
)

CommC2 <- Communities(PCclass2,
  Vcolor = Colors,
  Vsize = 7, Vcex = 0.3, main = "Modules AD Class 2"
)
par(opar)
```

```{r degree density plot }
# Plot the densities of centrality degree scores
plot(density(DegreesAD1[, 2]),
  col = "blue", xlim = c(-1, 8), xlab = "Degree", main = ""
)
lines(density(DegreesAD2[, 2]),
  col = "red"
)
legenda <- c("AD class 1", "AD class 2")
legend(5, 0.5,
  legend = legenda, 
  lwd = rep(1, 2), lty = rep(1, 2), col = c("blue", "red"), cex = 0.7
)
```

```{r wilcoxon rank sum }
# Perform a Wilcoxon signed rank test to test if the centrality degree scores are different between the classes
wilcox.test(DegreesAD1[, 2],
  DegreesAD2[, 2],
  paired = TRUE, alternative = "less"
)
```
