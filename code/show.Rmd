---
title: "Analysis"
output:
  html_document: 
    toc: yes
    toc_depth: 4
    theme: flatly
  pdf_document:
    toc: yes
  html_notebook: 
    toc: yes
    theme: flatly
    toc_depth: 5
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = "", warning = FALSE
)
```

```{r packages, include=FALSE}
require(caret)
require(glmnet)
require(dplyr)
require(e1071)
require(FMradio)
require(pROC)
require(rags2ridges)
require(xgboost)
require(ggthemes)
require(DMwR2)
require(globaltest)
require(heatmaply)
require(nnet)
```

## Data Exploration

The (interactive) correlation heatmap reveals very high correlation among TG compounds.

```{r heatmap}
load("./data.Rdata")
X <- df[df$Diagnosis == "Probable AD", 1:230]
C <- round(cor(X), 2)

heatmaply_cor(C, color = viridis, plot_method = "plotly", dendrogram = F, reorderfun = sort.default(d,w), main = "Correlation Heatmap", file = "heatmap.html", colorbar_thickness = 15, colorbar_len = 0.5)
```

## RQi: Differential expression of metabolites per ApoE genotype

### Global test

Performing a Global Test on the serum metabolites of AD patients, correcting for sex (Ho: E4 status has no effect on metabolite levels, Ha: it has an effect), yields a significant difference (p = 0.046) between E4 carriers and non-carriers. Testing if the counts of E4 alleles have an effect on metabolite levels showed no significant nuance.

```{r gt}
load("data.Rdata")
AD <- subset(df, Diagnosis == "Probable AD")
AD$sex <- as.numeric(AD$sex) -1
# Binary outcome
gt.b <- globaltest::gt(E4 ~ 1, E4 ~ . -APOE -Diagnosis, data = AD)
gt.b

# Multinomial outcome

full$Diagnosis <- as.numeric(full$Diagnosis) - 1
full$target[full$Diagnosis == 1 & full$E4 == 1] <- "AD with at least 1 ApoE4"
full$target[full$Diagnosis == 1 & full$E4 == 0] <- "AD without ApoE4"
full$target[full$Diagnosis == 0 & full$E4 == 1] <- "SCD with at least 1 ApoE4"
full$target[full$Diagnosis == 0 & full$E4 == 0] <- "SCD without ApoE4"
df$target <-  full$target
df$target <- as.factor(df$target)

AD$APOE <- as.factor(AD$APOE)
gt.m <- globaltest::gt(target ~ 1, target ~ . -APOE -E4 -Diagnosis - sex, data = df)
gt.m
gtmc <- covariates(gt.m)
plotly::ggplotly(gtmc, tooltip = "text", dynamicTicks = TRUE)
```


```{r}
anova <- function(Y, x, ...) {
  ### Analysis of Variance (ANOVA)
  df <- cbind(Y, x, ...)
  ncol <- ncol(Y)
  covariates <- names(...)
  summaries <- purrr::map(df[, 1:ncol], ~ {
    frm <- as.formula(paste0(".x ~", paste(covariates, collapse = "+")))
    rm <- lm(frm, data = df)
    ffm <- as.formula(paste0(".x ~ x +", paste(covariates, collapse = "+")))
    fm <- lm(ffm, data = df)
    anova(rm, fm)
  })
  ## Correction for Multiple Testing
  # Create a list to store the p-values
  p_values <- list(1:ncol)
  # Extract the p-values of the F-tests from the aov summaries list and store them in p_values
  for (i in 1:ncol) {
    p_values[[i]] <- summaries[[i]][["Pr(>F)"]][[2]]
  }
  # Coerce p_values to dataframe and transpose it
  p_values <- t(data.frame(p_values))

  # Set as row names the metabolites
  p_values <- data.frame(p_values, row.names = colnames(Y))

  # Calculate the FDR-adjusted p-values
  p_values$p_adj <- p.adjust(p_values[, ], method = "fdr")
  # Filter out the non-significant (a=0.05) FDR-adjusted p-values
  return(dplyr::filter(p_values, p_values < 0.05))
}
```

```{r}
Y <- df[, 1:230]
clinical$V_MMSE <- NULL
gentest(Y, target, clinical)
```

## RQii - Classification of metabolites on ApoE class
### Multinomial Classification of number of ApoE E4 alleles based on metabolites

```{r multifit}
multifit <- function(
                X,
                y,
                model,
                ctrl = NULL,
                grid = NULL,
                seed = 123, ...) {
  set.seed(seed)
  # Merge X and y into df
  df <- merge.data.frame(X, y)

  # Train the model
  mdl <- caret::train(df[, 1:ncol(X)], df$y,
    method = model,
    tuneGrid = grid,
    trControl = ctrl,
    metric = "logLoss",
    ...
  )
  # Create a confusion matrix and get performance metrics from caret
  obs <- mdl$pred$obs
  preds <- mdl$pred$pred
  cm <- confusionMatrix(obs, preds)
  # Predictions
  ys <- as.numeric(obs) -1
  yhats <- as.numeric(preds) -1
  roc <- multiclass.roc(ys, yhats)
  out <- list("cm" = cm, "roc" = roc, "model" = mdl)
  return(out)
}
```
#### Using 230 metabolites in AD
```{r multi_preparation}
X <- df[df$Diagnosis == "Probable AD", 1:230]
y <- df[df$Diagnosis == "Probable AD", "APOE"]
y <- as.factor(y)
levels(y) <- make.names(levels(y))

ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 50,
  classProbs = TRUE,
  summaryFunction = multiClassSummary,
  savePredictions = TRUE,
  sampling = "up"
)
```

##### Multinomial Logistic Regression

```{r mlogit}
mlr <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  tuneLength = 1
)
mlr$cm
```

##### Decision Tree

```{r }
mtree <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = expand.grid(maxdepth=c(2))
)
mtree$cm
```

##### XGBoost Forest

```{r multi_xgb}
mrf <- multifit(
  X = X,
  y = y,
  model = "xgbTree",
  ctrl = ctrl,
  grid = param
)
mrf$cm
```

```{r}
#Get a performance metrics table
multimetrics <- cbind(mlr$cm$byClass[3,], mtree$cm$byClass[3,], mrf$cm$byClass[3,])
multimetrics
#Plot ROC curves
mrocs <- list(mlr$roc, mtree$roc, mrf$roc)
# Generate labels
labels <- paste0(names(metrics), ", AUC = ", paste(round(metrics[12, ], 2)))
```

#### Projection to Latent Factors

```{r get_thomson, eval =FALSE, include=FALSE}
project <- function(X, m, seed) {
  set.seed(seed)
  X <- scale(as.matrix(X))
  cov <- cor(X)

  # Find redundant features
  filter <- RF(cov)

  # Filter out redundant features
  filtered <- subSet(X, filter)

  # Regularized correlation matrix estimation
  M <- regcor(filtered)

  # Get the regularized correlation matrix of the filtered dataset
  R <- M$optCor

  mlfa <- mlFA(R, m = m)
  thomson <- facScore(filtered, mlfa$Loadings, mlfa$Uniqueness)
  return(thomson)
}
```

```{r}

```
##### Multinomial Logistic Regression

```{r }

ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  classProbs = TRUE,
  summaryFunction = multiClassSummary,
  savePredictions = TRUE,
  sampling = "up"
)

mlrf <- multifit(
  X = X,
  y = y,
  model = "multinom",
  ctrl = ctrl,
  trace = FALSE,
  tuneLength = 1
)
mlrf$cm
```

##### Decision Tree

```{r multi_tree}
mtreef <- multifit(
  X = X,
  y = y,
  model = "rpart2",
  ctrl = ctrl,
  grid = mtree$model$bestTune
)
mtreef$cm
```

##### XGBoost Forest

```{r }
mrff <- multifit(
  X = X,
  y = y,
  model = "xgbTree",
  ctrl = ctrl,
  grid = param
)
mrff$cm
```

```{r}
# Get a performance metrics table
multimetricsf <- cbind(mlrf$cm$byClass[3, ], mtreef$cm$byClass[3, ], mrff$cm$byClass[3, ])
names(multimetricsf) <- names(metrics)
multimetricsf
```
